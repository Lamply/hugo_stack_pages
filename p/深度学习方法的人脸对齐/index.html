<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='这部分是去年 9 月份开始的工作，算是第一次真正踏入深度学习的领域。具体工作也还算简单，就是复现一篇深度学习方法做的人脸对齐，当练练手。
'><title>深度学习方法的人脸对齐</title>
<link rel=canonical href=/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/><link rel=stylesheet href=/scss/style.min.d8118f156935b64eca93aca758476adca858d2c47354971654d9bd2933a0e45f.css><meta property='og:title' content='深度学习方法的人脸对齐'><meta property='og:description' content='这部分是去年 9 月份开始的工作，算是第一次真正踏入深度学习的领域。具体工作也还算简单，就是复现一篇深度学习方法做的人脸对齐，当练练手。
'><meta property='og:url' content='/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/'><meta property='og:site_name' content='次二小栈'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='人脸对齐'><meta property='article:published_time' content='2018-07-19T00:00:00+00:00'><meta property='article:modified_time' content='2018-07-19T00:00:00+00:00'><meta property='og:image' content='/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1.png'><meta name=twitter:title content="深度学习方法的人脸对齐"><meta name=twitter:description content="这部分是去年 9 月份开始的工作，算是第一次真正踏入深度学习的领域。具体工作也还算简单，就是复现一篇深度学习方法做的人脸对齐，当练练手。
"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1.png'><link rel="shortcut icon" href=/letter-l.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/easy-peasy_50UJjNJE17_hua2b247eca74a7b47aad15a4079221f7e_48600_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>次二小栈</a></h1><h2 class=site-description>现在可以公开的笔记</h2></div></header><ol class=social-menu><li><a href=https://github.com/Lamply target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/%E9%93%BE%E6%8E%A5/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>链接</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#引言>引言</a></li><li><a href=#实现>实现</a></li><li><a href=#结果>结果</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/><img src=/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1_hu5c289e348364c1d3f31c9f2b61ccce7c_99390_800x0_resize_box_3.png srcset="/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1_hu5c289e348364c1d3f31c9f2b61ccce7c_99390_800x0_resize_box_3.png 800w, /p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1_hu5c289e348364c1d3f31c9f2b61ccce7c_99390_1600x0_resize_box_3.png 1600w" width=800 height=481 loading=lazy alt="Featured image of post 深度学习方法的人脸对齐"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%8A%80%E6%9C%AF%E7%BB%8F%E9%AA%8C/>技术经验</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/>深度学习方法的人脸对齐</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 19, 2018</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 3 分钟</time></div></footer></div></header><section class=article-content><p>这部分是去年 9 月份开始的工作，算是第一次真正踏入深度学习的领域。具体工作也还算简单，就是复现一篇深度学习方法做的人脸对齐，当练练手。</p><h2 id=引言>引言</h2><p>因为深度学习的发展，很多传统的计算机视觉技术有了突破性进展，市面上也涌现了不少以前技术无法做到的产品，传统的像人脸检测、人脸对齐方面也有很大进步。这里就谈谈其中的一个，Deep Alignment Network [1]（下面简写 DAN）。</p><p>DAN 是用卷积神经网络做人脸对齐的工作，大致思想就是级联卷积神经网络，每阶段都包含前一阶段的输出作为输入，输出 bias，加上 bias 并摆正人脸关键点和输入图，用 输出点生成的 heatmap + 最后一层卷积输出的特征 reshape 图 + 摆正后的原图 作为下一阶段的输入。这样就能不断修正，以达到 robust 的结果。</p><h2 id=实现>实现</h2><p>作者在 GitHub 上开源了代码 [2]，用的是 Theano 实现。除了验证集设置、initshape 部分冗余 和 测试的部分代码 外，其他部分应该都是没问题的，直接训练得到的结果除了 Challenging subset 稍微要差一些外，其他都和论文一致，算是比较好复现的一个了。</p><p>我用的是 caffe 做复现，一方面是方便部署到安卓，另一方面是简单好用，改起来也容易。当时还没有 TensorFlow Lite，从各个方面来说 TensorFlow 都不太方便。当然，现在 TensorFlow 就更厉害了。</p><p>大体上要做的事就是先实现一阶段，写好方便训练、测试用的 python 代码，把数据集封装成 hdf5。因为一阶段没用到自定义层，所以直接写出网络结构的 prototxt 和 solver 就能训练了，训练好后就能作为二阶的 pre-trained model。当然一阶相当于直接 VGG + 回归输出，所以也可以直接看到效果了，我训练出来测试结果如下（测试方法对应代码里的 centers，也就是 inter-pupil normalization error）:</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>Full set (%)</th><th style=text-align:center>Common subset (%)</th><th style=text-align:center>Challenging subset (%)</th></tr></thead><tbody><tr><td style=text-align:center>6.09</td><td style=text-align:center>5.29</td><td style=text-align:center>9.37</td></tr></tbody></table></div><p>因为训练过程稍有不同，参数也没怎么调，而且后面发现 heatmap 有一点小问题，这个结果和原代码一阶训练的结果有些差异（AUC 差大约 3%），不过无妨，这个结果已经比传统的方法要强得多了，我们继续二阶训练。</p><p>二阶大部分代码可以和一阶共用，主要要做的部分就是把论文提到的几个自定义层实现，对应这四个地方：</p><ol><li>根据第一阶预测的结果和 mean shape 对比求出仿射变换参数</li><li>根据仿射变换参数对输入图做仿射变换，也就是对正原图啦</li><li>根据仿射变换参数对第一阶预测的结果做仿射变换，当然还要包括反变换的实现</li><li>根据对正的一阶预测结果产生 heatmap</li></ol><p>然后还有一些 caffe 不支持的又比较常用的层，也就是 resize 层（也有叫 Interp 层或者 upsample 层，都是做插值，我个人认为最好用和部署框架相同的算法）。还有 loss 层，这个会影响到测试的结果和实际效果，我用的是和测试方法一致的度量来做 loss。</p><p>写好这些层的代码后还有两件事要做。一是单独测试每一层的输出，确保每层前向都各自没问题；二是要做 gradient check，保证反向传播的梯度数值正确。</p><p>完成一切之后，用一阶段模型作 pre-trained model，进行训练：</p><div align=center><img src=3.jpg width=80%><p>训练过程</p></div><h2 id=结果>结果</h2><p>最终结果：</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>Full set (%)</th><th style=text-align:center>Common subset (%)</th><th style=text-align:center>Challenging subset (%)</th></tr></thead><tbody><tr><td style=text-align:center>5.02</td><td style=text-align:center>4.30</td><td style=text-align:center>7.95</td></tr></tbody></table></div><p>可以看到和论文结果已经很接近了，这个任务也就大致完成了。比较遗憾的是这个网络不太好替换，后来我尝试把 backbone 从 VGG 更换成其他的轻量型网络，效果都不太理想，而且一到二阶段时由于三张原尺寸图 concat 做输入导致网络参数和运算量剧增也是一个很大的问题。另外，训练过程也可以看到存在非常大的过拟合。虽然有很多地方可以改进，不过毕竟不是首要的研发项目，所以后面就没有做下去了。</p><p>整个网络的结构框图如下：</p><figure align=center><img src=2.png width=40%></figure><p>[参考文献]:<br>[1] <a class=link href=https://arxiv.org/pdf/1706.01789.pdf target=_blank rel=noopener>《Deep Alignment Network: A convolutional neural network for robust face alignment》</a><br>[2] github: <a class=link href=https://github.com/MarekKowalski/DeepAlignmentNetwork target=_blank rel=noopener>MarekKowalski/DeepAlignmentNetwork</a></p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/>人脸对齐</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/><div class=article-image><img src=/p/%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%E7%9A%84%E4%BA%BA%E8%84%B8%E5%AF%B9%E9%BD%90/1.2e529b1b153c19a972c9b6eabeaac50f_hu5b645d07b6b062a706eff8df6053ecbe_497642_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post 传统方法的人脸对齐" data-hash="md5-LlKbGxU8GalyybbqvqrFDw=="></div><div class=article-details><h2 class=article-title>传统方法的人脸对齐</h2></div></a></article><article class=has-image><a href=/p/gfpgan%E5%B0%9D%E8%AF%95/><div class=article-image><img src=/p/gfpgan%E5%B0%9D%E8%AF%95/GFPGAN1.5cc13d88917ba0a95067b87c7186d50e_hua19e7be9ff06dc72a46a8fa9c415a192_43292_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post GFPGAN尝试" data-hash="md5-XME9iJF7oKlQZ7h8cYbVDg=="></div><div class=article-details><h2 class=article-title>GFPGAN尝试</h2></div></a></article><article><a href=/p/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%90%ABnan%E5%80%BC%E7%9A%84%E5%85%89%E6%B5%81%E5%9B%BE%E5%83%8F/><div class=article-details><h2 class=article-title>如何处理含nan值的光流图像</h2></div></a></article><article class=has-image><a href=/p/%E5%A6%82%E4%BD%95%E6%B6%88%E9%99%A4%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%97%B6%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94/><div class=article-image><img src=/p/%E5%A6%82%E4%BD%95%E6%B6%88%E9%99%A4%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%97%B6%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94/shot.0f7e8ca44fad4bcbf75bba298a3dfe8c_hua5252ff81ce67ad7cdcf3f8b04f4040e_26936_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post 如何消除图像生成时的棋盘效应" data-hash="md5-D36MpE+tS8v3W7opij3+jA=="></div><div class=article-details><h2 class=article-title>如何消除图像生成时的棋盘效应</h2></div></a></article><article><a href=/p/%E6%A8%A1%E5%9E%8B%E5%AB%81%E6%8E%A5/><div class=article-details><h2 class=article-title>模型嫁接</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=Lamply/hugo_stack_pages data-repo-id data-category data-category-id data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 次二小栈</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.23.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="/local.google.fonts.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
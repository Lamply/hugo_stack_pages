<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='这里是 ResNet 的论文，作为被广泛应用的骨干网络，它提出的几个概念可以说是 着实可靠 地拓宽了网络设计的思路，对于广大摸着石头过河的工程师和研究者来说就是指出了一条明路。网络本身也高效、简洁且实用，可以作为 VGG 的上位替代。
原文链接：Deep Residual Learning for Image Recognition
'><title>ResNet</title>
<link rel=canonical href=/p/resnet/><link rel=stylesheet href=/scss/style.min.d8118f156935b64eca93aca758476adca858d2c47354971654d9bd2933a0e45f.css><meta property='og:title' content='ResNet'><meta property='og:description' content='这里是 ResNet 的论文，作为被广泛应用的骨干网络，它提出的几个概念可以说是 着实可靠 地拓宽了网络设计的思路，对于广大摸着石头过河的工程师和研究者来说就是指出了一条明路。网络本身也高效、简洁且实用，可以作为 VGG 的上位替代。
原文链接：Deep Residual Learning for Image Recognition
'><meta property='og:url' content='/p/resnet/'><meta property='og:site_name' content='次二小栈'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2017-09-01T00:00:00+00:00'><meta property='article:modified_time' content='2017-09-01T00:00:00+00:00'><meta name=twitter:title content="ResNet"><meta name=twitter:description content="这里是 ResNet 的论文，作为被广泛应用的骨干网络，它提出的几个概念可以说是 着实可靠 地拓宽了网络设计的思路，对于广大摸着石头过河的工程师和研究者来说就是指出了一条明路。网络本身也高效、简洁且实用，可以作为 VGG 的上位替代。
原文链接：Deep Residual Learning for Image Recognition
"><link rel="shortcut icon" href=/letter-l.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/easy-peasy_50UJjNJE17_hua2b247eca74a7b47aad15a4079221f7e_48600_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>次二小栈</a></h1><h2 class=site-description>现在可以公开的笔记</h2></div></header><ol class=social-menu><li><a href=https://github.com/Lamply target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/%E9%93%BE%E6%8E%A5/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>链接</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#介绍>介绍</a></li><li><a href=#残差学习>残差学习</a></li><li><a href=#shortcut-恒等映射>shortcut 恒等映射</a></li><li><a href=#网络结构>网络结构</a></li><li><a href=#恒等和投影-shortcuts>恒等和投影 shortcuts</a></li><li><a href=#更深的瓶颈结构>更深的瓶颈结构</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/ style=background-color:#2a9d8f;color:#fff>论文笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/resnet/>ResNet</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Sep 01, 2017</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><p>这里是 ResNet 的论文，作为被广泛应用的骨干网络，它提出的几个概念可以说是 <strong>着实可靠</strong> 地拓宽了网络设计的思路，对于广大摸着石头过河的工程师和研究者来说就是指出了一条明路。网络本身也高效、简洁且实用，可以作为 VGG 的上位替代。</p><p>原文链接：<a class=link href=https://arxiv.org/abs/1512.03385 target=_blank rel=noopener>Deep Residual Learning for Image Recognition</a></p><h2 id=介绍>介绍</h2><p>网络深度对很多视觉任务都有很强的重要性, 但是仅靠简单的层堆积会存在梯度消失/爆炸问题. 虽然使用一些归一化初始技巧和中间归一化层可以很大程度解决这些问题, 但随着深度继续增加, 网络的精准度会逐渐饱和, 接着就会快速劣化, 这就是 <em>degradation problem</em>. 出乎意料的是, 这些问题不是因为过拟合导致的, 实验证明增加更多的层数会导致更高的 <em>训练误差</em>.<br>本文, 作者通过引入一个深度残差学习框架解决了这个 degradation problem. 与其让每几个堆叠的层直接学习潜在的映射, 我们显式地让这些层去学习残差映射. 正式来讲, 即输出 H(x), 输入 x, 让非线性层学习 F(x):=H(x)-x, 那么原本的映射就变成了 F(x)+x. 这在前向网络中会被视为捷径 ( &ldquo;<em>shortcut connections</em>&rdquo; ), 允许网络跳级连接, 在本文中可以简单看成 <em>恒等映射 ( &ldquo;identity mapping&rdquo; )</em>.<br>经过实验发现, 深度残差网很容易训练, 且很容易让精度随网络深度的增加而增加.</p><h2 id=残差学习>残差学习</h2><p>假设多次非线性函数能够渐进逼近复杂函数, 那么在维度不变的情况下该假设与渐进逼近残差是一样的.<br>之所以改为学习残差, 是因为 degradation problem 这个反常的现象. 在残差学习的恒等映射情况下, 一个更深的模型的训练误差是应该不超过比它浅的模型的. degradation problem 告诉我们 solver 使用多次非线性函数在渐进逼近恒等映射时可能存在困难, 而残差学习则提供了将权重趋向 0 来达到恒等映射的拟合.<br>当然, 在现实中, 恒等映射不太可能是最优的. 但这个改动可能有助于先决这个问题. 如果最优函数接近于恒等映射而非零映射, 那么 solver 应该很容易学习扰动来得到最优函数. 通过实验发现, 通常残差函数只有很小的响应, 这表明恒等映射的可以提供合理的先决条件.</p><h2 id=shortcut-恒等映射>shortcut 恒等映射</h2><p>本文采用每叠一些层就使用残差学习, 也就是建立一个 block:
$$y=F(x,W)+x$$
其中:
$$F = W_2\sigma(W_1x)$$
σ 为 ReLU, 省略了 bias. 在得到 y 后再做一次 ReLU.<br>如果需要变化维度, 则:
$$y=F(x,W)+W_sx$$
W_s 为投影矩阵, 用来改变维度, 当然它也可以是个方阵用作线性变换, 但后续实验证明恒等变换就足够解决 degradation problem 了.<br>F 是可以灵活改变的, 可以含有多层, 或者不同类型的层, 比如卷积层. 但如果 F 仅含有一层映射的话, 那还没有得到有效的效果验证.</p><h2 id=网络结构>网络结构</h2><p>为了对比, 作者构建了两个相同计算量的网络, 两种网络均为类似 VGG 的网络. 开始 7x7 stride 2, 然后 3x3, 每降低一次 feature map, double 一次 filters 数量, 使用 stride 2 卷积来降低 feature map, 堆叠 34 层和类似的 18 层. 最后做全局平均池化, 然后接 1000 分类器, 卷积后面都采用了 batch normalization 保证训练不失败.<br>不同的是 ResNet 版加入了跳级连接, 降低 feature map 提升维度处分成两种策略, 一种填充 0 来扩增维度, 另一种上述提到的 1x1 升维, 两种方法都 stride 2 降低空间大小.<br>实验得知, VGG 34 层表现比 18 层要差. 而且经过更多 iter 的训练发现问题没有解决.<br>对于 ResNet 版, 采取第一种策略的, 34 层比 18 层错误率要少 2.8%, 更重要的, 34 层表现出明显更低的训练误差, 并且能很好泛化验证数据.<br>对比两种网络的 18 层版, 发现 ResNet 能在训练早期更快的收敛.</p><p>ImageNet 上 10-crop top-1 error 实验结果如下:</p><div class=table-wrapper><table><thead><tr><th style=text-align:center></th><th style=text-align:center>plain</th><th style=text-align:center>ResNet</th></tr></thead><tbody><tr><td style=text-align:center>18 layers</td><td style=text-align:center>27.94</td><td style=text-align:center>27.88</td></tr><tr><td style=text-align:center>34 layers</td><td style=text-align:center>28.54</td><td style=text-align:center>25.03</td></tr><tr><td style=text-align:center>(PS: <em>看上去似乎浅层下 ResNet 影响不大</em> )</td><td></td><td></td></tr></tbody></table></div><h2 id=恒等和投影-shortcuts>恒等和投影 shortcuts</h2><p>对比 ResNet 不同策略, 分为三种对比:</p><ol><li>零填充升维, 所有 shortcuts 都没有参数</li><li>升维时使用 1x1 卷积升维, 其他恒等</li><li>所有 shortcuts 都带有 1x1 卷积<br>实验表明, 2 稍微比 1 好些 <code>(top-1 25.03->24.52)</code>, 作者认为这是因为 1 在升维时的零填充部分实际并没有进行残差学习; 3 轻微比 2 好些 <code>(top-1 24.52->24.19)</code>, 作者认为这是因为 3 在 shortcuts 处引入了额外参数. 微小的差异表明投影 shortcuts 对与解决 degradation problem 不重要.</li></ol><h2 id=更深的瓶颈结构>更深的瓶颈结构</h2><p>为了节省训练时间, 作者把上面的 block 修改为 瓶颈 ( <em>bottleneck</em> ) 设计. 即在每个 $F$ 内堆叠三层, 分别为 1x1, 3x3, 1x1 卷积层. 其中 1x1 用于升降维度, 使 3x3 作为有更低输入输出维度的瓶颈.</p><div align=center><img src=block.png></div><p>对于瓶颈结构来说, shortcuts 策略的选择对模型大小和时间复杂度都有很重要的影响, 无参数恒等 shortcuts 可以让瓶颈模型更高效. ( <em>?</em> )</p><p>作者在 50/101/152 层模型中使用了瓶颈结构和策略2的升降维.其各个配置如下:</p><div align=center><img src=Configuration.png></div><p>（PS: <em>值得注意的是 ResNet 50 层瓶颈版的 FLOPs 与 34 层相差不大, 网络的堆叠配置是一样的</em>）</p><p>在 ImageNet 验证集上的 10-crop 实验结果如下:</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>method</th><th style=text-align:center>top-1 err.</th><th style=text-align:center>top-5 err.</th></tr></thead><tbody><tr><td style=text-align:center>plain-34</td><td style=text-align:center>28.54</td><td style=text-align:center>10.02</td></tr><tr><td style=text-align:center>ResNet-34 1</td><td style=text-align:center>25.03</td><td style=text-align:center>7.76</td></tr><tr><td style=text-align:center>ResNet-34 2</td><td style=text-align:center>24.52</td><td style=text-align:center>7.46</td></tr><tr><td style=text-align:center>ResNet-34 3</td><td style=text-align:center>24.19</td><td style=text-align:center>7.40</td></tr><tr><td style=text-align:center>ResNet-50</td><td style=text-align:center>22.85</td><td style=text-align:center>6.71</td></tr><tr><td style=text-align:center>ResNet-101</td><td style=text-align:center>21.75</td><td style=text-align:center>6.05</td></tr><tr><td style=text-align:center>ResNet-152</td><td style=text-align:center>21.43</td><td style=text-align:center>5.71</td></tr></tbody></table></div><p>在 ImageNet 验证集上单模型实验结果如下:</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>method</th><th style=text-align:center>top-1 err.</th><th style=text-align:center>top-5 err.</th></tr></thead><tbody><tr><td style=text-align:center>ResNet-34 2</td><td style=text-align:center>21.84</td><td style=text-align:center>5.71</td></tr><tr><td style=text-align:center>ResNet-34 3</td><td style=text-align:center>21.53</td><td style=text-align:center>5.60</td></tr><tr><td style=text-align:center>ResNet-50</td><td style=text-align:center>20.74</td><td style=text-align:center>5.25</td></tr><tr><td style=text-align:center>ResNet-101</td><td style=text-align:center>19.87</td><td style=text-align:center>4.60</td></tr><tr><td style=text-align:center>ResNet-152</td><td style=text-align:center>19.38</td><td style=text-align:center>4.49</td></tr><tr><td style=text-align:center>最终在 ILSVRC 2015 提交中使用了两个 152 层模型的 ensembles, 得到 top-5 error 3.57.</td><td></td><td></td></tr></tbody></table></div></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/stylegan/><div class=article-image><img src=/p/stylegan/arch1.66d8dda14bf460b7493b1d8a7ab276a7_hub988efc80824a295e46270c7ce0704e1_32816_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post StyleGAN" data-hash="md5-ZtjdoUv0YLdJOx2KerJ2pw=="></div><div class=article-details><h2 class=article-title>StyleGAN</h2></div></a></article><article class=has-image><a href=/p/pix2pixhd/><div class=article-image><img src=/p/pix2pixhd/pix2pix_arch.252df59247ccb2fc9c190966eb1fd3d7_hu6199731767d3a35c48a188e67800c4b9_22146_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post Pix2PixHD" data-hash="md5-JS31kkfMsvycGQlm6x/T1w=="></div><div class=article-details><h2 class=article-title>Pix2PixHD</h2></div></a></article><article><a href=/p/deeplab%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E7%AE%80%E7%95%A5%E8%AE%B0%E5%BD%95/><div class=article-details><h2 class=article-title>DeepLab系列论文简略记录</h2></div></a></article><article><a href=/p/mobilenet-v2/><div class=article-details><h2 class=article-title>MobileNet V2</h2></div></a></article><article><a href=/p/shufflenet/><div class=article-details><h2 class=article-title>ShuffleNet</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=Lamply/hugo_stack_pages data-repo-id data-category data-category-id data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 次二小栈</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.23.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="/local.google.fonts.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>
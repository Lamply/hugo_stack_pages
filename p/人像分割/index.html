<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='这部分是关于在低计算量下完成人像分割的工作，因为时间充裕，所以调查尝试得比较多，最终完成的效果还不错。
'><title>人像分割</title>
<link rel=canonical href=/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/><link rel=stylesheet href=/scss/style.min.d8118f156935b64eca93aca758476adca858d2c47354971654d9bd2933a0e45f.css><meta property='og:title' content='人像分割'><meta property='og:description' content='这部分是关于在低计算量下完成人像分割的工作，因为时间充裕，所以调查尝试得比较多，最终完成的效果还不错。
'><meta property='og:url' content='/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/'><meta property='og:site_name' content='次二小栈'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='语义分割'><meta property='article:published_time' content='2019-04-19T00:00:00+00:00'><meta property='article:modified_time' content='2019-04-19T00:00:00+00:00'><meta property='og:image' content='/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/Einstein.png'><meta name=twitter:title content="人像分割"><meta name=twitter:description content="这部分是关于在低计算量下完成人像分割的工作，因为时间充裕，所以调查尝试得比较多，最终完成的效果还不错。
"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/Einstein.png'><link rel="shortcut icon" href=/letter-l.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/easy-peasy_50UJjNJE17_hua2b247eca74a7b47aad15a4079221f7e_48600_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>次二小栈</a></h1><h2 class=site-description>现在可以公开的笔记</h2></div></header><ol class=social-menu><li><a href=https://github.com/Lamply target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/%E9%93%BE%E6%8E%A5/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>链接</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#引言>引言</a></li><li><a href=#实现>实现</a><ol><li><a href=#数据集>数据集</a></li><li><a href=#设计>设计</a></li><li><a href=#训练>训练</a></li><li><a href=#测试>测试</a></li></ol></li><li><a href=#最终的效果>最终的效果</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/><img src=/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/Einstein_hu425a277444e3247e832d80bb1c186570_489948_800x0_resize_box_3.png srcset="/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/Einstein_hu425a277444e3247e832d80bb1c186570_489948_800x0_resize_box_3.png 800w, /p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/Einstein_hu425a277444e3247e832d80bb1c186570_489948_1600x0_resize_box_3.png 1600w" width=800 height=798 loading=lazy alt="Featured image of post 人像分割"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%8A%80%E6%9C%AF%E7%BB%8F%E9%AA%8C/>技术经验</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/%E4%BA%BA%E5%83%8F%E5%88%86%E5%89%B2/>人像分割</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 19, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 4 分钟</time></div></footer></div></header><section class=article-content><p>这部分是关于在低计算量下完成人像分割的工作，因为时间充裕，所以调查尝试得比较多，最终完成的效果还不错。</p><h2 id=引言>引言</h2><p>人像分割（portrait segmentation）属于语义分割的子集，某种程度上类似于只专注人的前景分割，可以看成是二分类的语义分割。不过这里的应用场景是半身肖像，对于效果的评价更加专注于分割边缘和细节的质量，现在看来这次的工作在这方面其实做得比较一般，只是就通常的 IoU 意义上来看还不错。</p><p>总体来说，人像分割方面的论文比较少，典型的就是 Xiaoyong Shen 等人的工作 [1] [2]。不过实际尝试过程中发现，其中的很多技巧无法有效的应用于低计算量的场景中，固定先验的引入也会导致分割效果在某些情况下变差。</p><h2 id=实现>实现</h2><h3 id=数据集>数据集</h3><p>数据集方面因为我采取了逐步迁移训练，多次 fine-tuning 的方式，所以需要从 ImageNet 到 COCO 人像子集再到标准半身人像分割的数据集。COCO 人像子集是从 COCO 中筛选出含人类（且占面积较大）的部分，大约 4 万张；半身人像分割的数据集训练集一千多张，验证集 50 张，测试集 300 张；还有一些私有的测试集。<br>之所以这样做主要是因为最终用于应用场景的数据集过少，而且从 OSVOS[3] 等文中得到了更多的启发。</p><div align=center><img src=osvos.png>
OSVOS 的做法</div><h3 id=设计>设计</h3><p>我主要尝试了 ENet [4]、FCN [5]、FCN dilated convolution 版本 [6]、UNet [7] 的改进版 以及 类 DeepLab V3+ [8] 中的方法。为了保持计算量，除了 [4] 外，我都采用了轻量化网络 ShuffleNet [9] 作为 backbone 来进行复现，大部分网络的输入限制为 224x224。</p><p>对于 UNet 的改进版，因为是冲着实时而设计的，所以在 decoder 的设计上，尤其是底层特征的引入上显著减少了滤波器数量。当 output stride 为 4 时，可以得到的模型性能为：参数量 79.54K, FLOPS 24.44M, 访存量 46.98MB，可以达到实时。</p><p>对于类 DeepLab V3+ 的版本，为了尽可能的压缩计算量，我最大限度的利用了 Depthwise Convolution、Dilation 以及 Channel Shuffle 的特性，同时为平衡精度将 output stride 限制为 2（损失非常少），decoder 也改成了更为节省计算量的简单版本，模型性能为：参数量 965.49K, FLOPS 743.37M, 访存量 392.87MB。</p><blockquote><ul><li><em>来自底层特征的 skip-connection 是有很明显的边缘细化效果的，但同时也十分容易过拟合，这是值得注意的问题。</em></li></ul></blockquote><ul><li><em>尽管我把 ASPP 写的很省，但尝试后发现如果那个结构不加 ASPP 的话性能会很差。</em></li><li><em>关于深度，尝试的结果似乎说明了 Encoder 部分需要足够的深（至少 8 个 res block 是不够的），而 Decoder 则不需要太复杂（没有足够的证据，不过增加 2 层能带来的好处不大）</em></li></ul><h3 id=训练>训练</h3><p>训练方面，UNet（实时） 和 类 DeepLab V3+ 方法因为是从头搭起，所以就像上面说的一样，需要两次 fine-tuning，其余方法并没有经过 COCO 人像预训练。优化方法我用的是 SGD+Momentum，事实上这是因为用其他的一些优化方法会导致“零核现象”的发生，我在以前的一篇文章中分析过这点，不知道这个现象和性能的下降有多大关系，但如果用 SGD 的话就不会有这种事情发生，而且性能会更好。</p><blockquote><ul><li><em>COCO 人像部分的预训练的加入很有效，但是必须使用和应用场景十分相似的部分作为预训练才有效，不筛选的话很可能没有效果上的影响。</em></li></ul></blockquote><ul><li><em>使用大 Momentum（我用的 0.99）似乎不错，训练速度会很快而且效果也不会差（实验尝试似乎比 0.9 还要好）。</em></li><li><em>实际训练时还发现有挺严重的过拟合，所以做了些数据集扩增，结果挺有效的。</em></li><li><em>在 output stride 为 8 时增加一个辅助损失也是有效的。</em></li></ul><h3 id=测试>测试</h3><p>在 [1] 中给出的数据集中测试结果如下（其中我加入了 Std 度量用于观察分割的稳定性，意为 IoU 的标准差）</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>Method</th><th style=text-align:center>mIoU</th><th style=text-align:center>Std</th></tr></thead><tbody><tr><td style=text-align:center>ENet</td><td style=text-align:center>94.04%</td><td style=text-align:center>6.25%</td></tr><tr><td style=text-align:center>FCN</td><td style=text-align:center>95.73%</td><td style=text-align:center>3.10%</td></tr><tr><td style=text-align:center>FCN + dilated</td><td style=text-align:center>96.04%</td><td style=text-align:center>3.27%</td></tr><tr><td style=text-align:center>UNet（实时）</td><td style=text-align:center>95.32%</td><td style=text-align:center>4.03%</td></tr><tr><td style=text-align:center>类 DeepLab V3+</td><td style=text-align:center>96.4%</td><td style=text-align:center>3.25%</td></tr><tr><td style=text-align:center>PortraitFCN+[1]</td><td style=text-align:center>95.91%</td><td style=text-align:center>-</td></tr></tbody></table></div><p>另外我还自己标了个五十多张明暗、运动、背景复杂度变化都比较大的测试图片，在此数据集上测试结果为</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>Method</th><th style=text-align:center>mIoU</th><th style=text-align:center>Std</th></tr></thead><tbody><tr><td style=text-align:center>ENet</td><td style=text-align:center>61.42%</td><td style=text-align:center>20.04%</td></tr><tr><td style=text-align:center>FCN</td><td style=text-align:center>87.71%</td><td style=text-align:center>12.01%</td></tr><tr><td style=text-align:center>FCN + dilated</td><td style=text-align:center>89.43%</td><td style=text-align:center>10.62%</td></tr><tr><td style=text-align:center>UNet（实时）</td><td style=text-align:center>91.96%</td><td style=text-align:center>3.95%</td></tr><tr><td style=text-align:center>类 DeepLab V3+</td><td style=text-align:center>93.7%</td><td style=text-align:center>2.3%</td></tr></tbody></table></div><p>可以看到类 DeepLab V3+ 方法测试结果还是挺不错的，其余的多个私有测试集上表现也不错，它在 MIX2 上前向一张图片大概需要 120ms。除此之外，达到实时性能的 UNet 改进版也不错，两者在 P-R 曲线上差异不是很大。</p><div align=center><img src=performance.png width=80%>
非实时与实时网络的 P-R 曲线比较</div><h2 id=最终的效果>最终的效果</h2><div align=center><img src=full.png width=70%></div><p>可以看到边缘的跟踪还是不错的，除此之外，头发的细节处理也可以在顶部图中看到。</p><p>因为 output stride 为 2 导致分割边缘在放大后加大了间隔，看上去和实际边缘有些距离。在下面的图中可以明显看到这种在人和物件之间的边界、甚至透明物件覆盖影响下算法的处理情况。</p><div align=center><img src=pony.png width=70%></div><p>虽然训练集全都是单人肖像，但多人的情况也能够分割，具体效果还是要看人物所占的尺度等。</p><div align=center><img src=multi.jpg width=70%></div><p>[参考文献]:<br>[1] <a class=link href=http://xiaoyongshen.me/webpage_portrait/papers/portrait_eg16.pdf target=_blank rel=noopener>《Automatic Portrait Segmentation for Image Stylization》</a><br>[2] <a class=link href=https://arxiv.org/pdf/1704.08812.pdf target=_blank rel=noopener>《Automatic Real-time Background Cut for Portrait Videos》</a><br>[3] <a class=link href=http://openaccess.thecvf.com/content_cvpr_2017/papers/Caelles_One-Shot_Video_Object_CVPR_2017_paper.pdf target=_blank rel=noopener>《One-Shot Video Object Segmentation》</a><br>[4] <a class=link href=https://arxiv.org/pdf/1606.02147.pdf target=_blank rel=noopener>《ENet: A Deep Neural Network Architecture forReal-Time Semantic Segmentation》</a><br>[5] <a class=link href=https://arxiv.org/pdf/1411.4038.pdf target=_blank rel=noopener>《Fully Convolutional Networks for Semantic Segmentation》</a><br>[6] <a class=link href=https://arxiv.org/pdf/1702.08502.pdf target=_blank rel=noopener>《Understanding Convolution for Semantic Segmentation》</a><br>[7] <a class=link href=https://arxiv.org/pdf/1505.04597.pdf target=_blank rel=noopener>《U-Net: Convolutional Networks for BiomedicalImage Segmentation》</a><br>[8] <a class=link href=https://arxiv.org/pdf/1802.02611.pdf target=_blank rel=noopener>《Encoder-Decoder with Atrous SeparableConvolution for Semantic Image Segmentation》</a><br>[9] <a class=link href=https://arxiv.org/pdf/1707.01083.pdf target=_blank rel=noopener>《ShuffleNet: An Extremely Efficient Convolutional Neural Network for MobileDevices》</a></p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/>语义分割</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/gfpgan%E5%B0%9D%E8%AF%95/><div class=article-image><img src=/p/gfpgan%E5%B0%9D%E8%AF%95/GFPGAN1.5cc13d88917ba0a95067b87c7186d50e_hua19e7be9ff06dc72a46a8fa9c415a192_43292_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post GFPGAN尝试" data-hash="md5-XME9iJF7oKlQZ7h8cYbVDg=="></div><div class=article-details><h2 class=article-title>GFPGAN尝试</h2></div></a></article><article><a href=/p/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%90%ABnan%E5%80%BC%E7%9A%84%E5%85%89%E6%B5%81%E5%9B%BE%E5%83%8F/><div class=article-details><h2 class=article-title>如何处理含nan值的光流图像</h2></div></a></article><article class=has-image><a href=/p/%E5%A6%82%E4%BD%95%E6%B6%88%E9%99%A4%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%97%B6%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94/><div class=article-image><img src=/p/%E5%A6%82%E4%BD%95%E6%B6%88%E9%99%A4%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%97%B6%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94/shot.0f7e8ca44fad4bcbf75bba298a3dfe8c_hua5252ff81ce67ad7cdcf3f8b04f4040e_26936_250x150_fill_box_smart1_3.png width=250 height=150 loading=lazy alt="Featured image of post 如何消除图像生成时的棋盘效应" data-hash="md5-D36MpE+tS8v3W7opij3+jA=="></div><div class=article-details><h2 class=article-title>如何消除图像生成时的棋盘效应</h2></div></a></article><article><a href=/p/%E6%A8%A1%E5%9E%8B%E5%AB%81%E6%8E%A5/><div class=article-details><h2 class=article-title>模型嫁接</h2></div></a></article><article><a href=/p/%E7%AE%97%E6%B3%95%E5%8A%A0%E9%80%9F%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/><div class=article-details><h2 class=article-title>算法加速的几种方法</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=Lamply/hugo_stack_pages data-repo-id data-category data-category-id data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 次二小栈</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.23.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="/local.google.fonts.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>